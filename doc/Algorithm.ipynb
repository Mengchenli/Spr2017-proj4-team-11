{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages and specify the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import numba\n",
    "from scipy.misc import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorNum</th>\n",
       "      <th>paperNum</th>\n",
       "      <th>paperTitle</th>\n",
       "      <th>journalTitle</th>\n",
       "      <th>coauthor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>PMES: privilege mangagement and enforcement sy...</td>\n",
       "      <td>ifip|international|federation|information|proc...</td>\n",
       "      <td>b kvande|i levinstein|k maly|m olson|r mukkama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>CoProcess: A Java-based Environment for Collab...</td>\n",
       "      <td>webnet</td>\n",
       "      <td>c vemuru|h syed|h abdel-wahab|k maly|m kholief...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>A privilege management and enforcement system ...</td>\n",
       "      <td>wetice|workshop|enabling|technologies|infrastr...</td>\n",
       "      <td>b kvande|i levinstein|k maly|m olson|r mukkama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>The software architecture and interprocess com...</td>\n",
       "      <td>wetice|workshop|enabling|technologies|infrastr...</td>\n",
       "      <td>a youssef|c overstreet|e stoica|h abdel-wahab|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Mosaic + XTV = CoReview</td>\n",
       "      <td>computer|networks|isdn|systems</td>\n",
       "      <td>a prabhu|c vemuru|h syed|h abdel-wahab|k maly|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorNum  paperNum                                         paperTitle  \\\n",
       "0         10         1  PMES: privilege mangagement and enforcement sy...   \n",
       "1         10         2  CoProcess: A Java-based Environment for Collab...   \n",
       "2         10         3  A privilege management and enforcement system ...   \n",
       "3         10         4  The software architecture and interprocess com...   \n",
       "4         10         5                           Mosaic + XTV = CoReview    \n",
       "\n",
       "                                        journalTitle  \\\n",
       "0  ifip|international|federation|information|proc...   \n",
       "1                                             webnet   \n",
       "2  wetice|workshop|enabling|technologies|infrastr...   \n",
       "3  wetice|workshop|enabling|technologies|infrastr...   \n",
       "4                     computer|networks|isdn|systems   \n",
       "\n",
       "                                            coauthor  \n",
       "0  b kvande|i levinstein|k maly|m olson|r mukkama...  \n",
       "1  c vemuru|h syed|h abdel-wahab|k maly|m kholief...  \n",
       "2  b kvande|i levinstein|k maly|m olson|r mukkama...  \n",
       "3  a youssef|c overstreet|e stoica|h abdel-wahab|...  \n",
       "4  a prabhu|c vemuru|h syed|h abdel-wahab|k maly|...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/text1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.journalTitle = df.journalTitle.fillna('')\n",
    "df.coauthor = df.coauthor.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.journalTitle = [x.split(\"|\") for x in df.journalTitle.tolist()]\n",
    "df.coauthor = [x.split(\"|\") for x in df.coauthor.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorNum</th>\n",
       "      <th>paperNum</th>\n",
       "      <th>paperTitle</th>\n",
       "      <th>journalTitle</th>\n",
       "      <th>coauthor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>PMES: privilege mangagement and enforcement sy...</td>\n",
       "      <td>[ifip, international, federation, information,...</td>\n",
       "      <td>[b kvande, i levinstein, k maly, m olson, r mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>CoProcess: A Java-based Environment for Collab...</td>\n",
       "      <td>[webnet]</td>\n",
       "      <td>[c vemuru, h syed, h abdel-wahab, k maly, m kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>A privilege management and enforcement system ...</td>\n",
       "      <td>[wetice, workshop, enabling, technologies, inf...</td>\n",
       "      <td>[b kvande, i levinstein, k maly, m olson, r mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>The software architecture and interprocess com...</td>\n",
       "      <td>[wetice, workshop, enabling, technologies, inf...</td>\n",
       "      <td>[a youssef, c overstreet, e stoica, h abdel-wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Mosaic + XTV = CoReview</td>\n",
       "      <td>[computer, networks, isdn, systems]</td>\n",
       "      <td>[a prabhu, c vemuru, h syed, h abdel-wahab, k ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorNum  paperNum                                         paperTitle  \\\n",
       "0         10         1  PMES: privilege mangagement and enforcement sy...   \n",
       "1         10         2  CoProcess: A Java-based Environment for Collab...   \n",
       "2         10         3  A privilege management and enforcement system ...   \n",
       "3         10         4  The software architecture and interprocess com...   \n",
       "4         10         5                           Mosaic + XTV = CoReview    \n",
       "\n",
       "                                        journalTitle  \\\n",
       "0  [ifip, international, federation, information,...   \n",
       "1                                           [webnet]   \n",
       "2  [wetice, workshop, enabling, technologies, inf...   \n",
       "3  [wetice, workshop, enabling, technologies, inf...   \n",
       "4                [computer, networks, isdn, systems]   \n",
       "\n",
       "                                            coauthor  \n",
       "0  [b kvande, i levinstein, k maly, m olson, r mu...  \n",
       "1  [c vemuru, h syed, h abdel-wahab, k maly, m kh...  \n",
       "2  [b kvande, i levinstein, k maly, m olson, r mu...  \n",
       "3  [a youssef, c overstreet, e stoica, h abdel-wa...  \n",
       "4  [a prabhu, c vemuru, h syed, h abdel-wahab, k ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coauthor</th>\n",
       "      <th>journalTitle</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[b kvande, i levinstein, k maly, m olson, r mu...</td>\n",
       "      <td>[ifip, international, federation, information,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c vemuru, h syed, h abdel-wahab, k maly, m kh...</td>\n",
       "      <td>[webnet]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[b kvande, i levinstein, k maly, m olson, r mu...</td>\n",
       "      <td>[wetice, workshop, enabling, technologies, inf...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[a youssef, c overstreet, e stoica, h abdel-wa...</td>\n",
       "      <td>[wetice, workshop, enabling, technologies, inf...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[a prabhu, c vemuru, h syed, h abdel-wahab, k ...</td>\n",
       "      <td>[computer, networks, isdn, systems]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            coauthor  \\\n",
       "0  [b kvande, i levinstein, k maly, m olson, r mu...   \n",
       "1  [c vemuru, h syed, h abdel-wahab, k maly, m kh...   \n",
       "2  [b kvande, i levinstein, k maly, m olson, r mu...   \n",
       "3  [a youssef, c overstreet, e stoica, h abdel-wa...   \n",
       "4  [a prabhu, c vemuru, h syed, h abdel-wahab, k ...   \n",
       "\n",
       "                                        journalTitle  label  \n",
       "0  [ifip, international, federation, information,...     10  \n",
       "1                                           [webnet]     10  \n",
       "2  [wetice, workshop, enabling, technologies, inf...     10  \n",
       "3  [wetice, workshop, enabling, technologies, inf...     10  \n",
       "4                [computer, networks, isdn, systems]     10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use partial features to test the algorithm\n",
    "features = ['coauthor','journalTitle']\n",
    "label = 'authorNum'\n",
    "my_df = df[features]\n",
    "my_df.ix[:,'label'] = df[label].tolist()\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def p_similarity(r1,r2):\n",
    "    '''\n",
    "    #parameters : r1,r2 are 2 array of arrays, e.g. [['a1','a2','a3'],['t1','t2']],[['a1','a4'],['t2','t5']]\n",
    "    #output: sim is the weighted similarity between r1 and r2\n",
    "    '''\n",
    "    k1 = np.intersect1d(r1[0],r2[0]).shape[0]\n",
    "    k2 = np.intersect1d(r1[1],r2[1]).shape[0]\n",
    "    sim = np.array((k1,k2))\n",
    "    return sim    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_sml(r1,r2):\n",
    "    '''\n",
    "    parameters : r1,r2 are 2 array of arrays, e.g. [['a1','a2','a3'],['t1','t2']],[['a1','a4'],['t2','t5']]\n",
    "                 w is an array, the weight parameter to adjust importance of each feature, shape is (n_feature,)\n",
    "    output: sim is the similarity vector between r1 and r2\n",
    "    '''\n",
    "    k1 = np.intersect1d(r1[0],r2[0]).shape[0]\n",
    "    k2 = np.intersect1d(r1[1],r2[1]).shape[0]\n",
    "    sim = np.array((k1,k2))\n",
    "    return sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.65 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 56.3 µs per loop\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "r1,r2 = my_df.ix[:,features].values[:2,]\n",
    "#r1 = df.ix[1,].values\n",
    "#r2 = df.ix[1,['coauthor','journalTitle']].values\n",
    "w = np.array([0.5,0.5])\n",
    "%timeit p_sml(r1,r2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p_sml(r1,r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def C_similarity(d):\n",
    "    '''\n",
    "    #parameters: d1 is a clusters, an array of dim nc_records*n_feature\n",
    "    #output: sim is the weighted similarity within a cluster\n",
    "    '''\n",
    "    if len(d.shape)==1:\n",
    "        d = d.reshape(1,2)\n",
    "        d = np.concatenate((d,d))\n",
    "    nc = d.shape[0]\n",
    "    sim = 0\n",
    "    for i in range(nc-1):\n",
    "        for j in range((i+1),nc):\n",
    "            sim += p_similarity(d[i,],d[j,])\n",
    "    return (sim/(nc*(nc-1)*1.0))   \n",
    "'''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.71 s per loop\n"
     ]
    }
   ],
   "source": [
    "#d = my_df.ix[:,features].values[:289,]\n",
    "#%timeit C_similarity(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02670848,  0.17471646])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C_similarity(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def C_sml(d1,d2):\n",
    "    '''\n",
    "    parameters: d1, d2 are 2 clusters, each is an array of dim nc_records*n_feature\n",
    "                w is the weight parameter, shape is (n_feature,)\n",
    "    output: sim is the similarity vector between 2 clusters\n",
    "    '''\n",
    "    if len(d1.shape)==1:\n",
    "        d1 = d1.reshape((1,d1.shape[0]))\n",
    "    if len(d2.shape)==1:\n",
    "        d2 = d2.reshape((1,d2.shape[0]))\n",
    "    nc_1 = d1.shape[0]\n",
    "    nc_2 = d2.shape[0]\n",
    "    sim = 0\n",
    "    for i in range(nc_1):\n",
    "        for j in range(nc_2):\n",
    "            sim += p_sml(d1[i,],d2[j,])\n",
    "    return (sim/(nc_1*nc_2*1.0))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.98 s per loop\n"
     ]
    }
   ],
   "source": [
    "#d1 = my_df.ix[:,features].values[:289,]\n",
    "#d2 = my_df.ix[:,features].values[289:,]\n",
    "#%timeit C_sml(d1,d2,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00843426,  0.31251201])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C_sml(d1,d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  0.])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C_sml(r1,r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# feature 1: one gram overlapping\n",
    "#@numba.jit\n",
    "def cmOneGram(d):\n",
    "    # d is a pair of elements in a feature\n",
    "    cm_w = len(set(d[0]).intersection(set(d[1])))\n",
    "    return cm_w\n",
    "% timeit cmOneGram(df.ix[[1,3],'coauthor'].tolist())\n",
    "# how many coauthors in average does a cluster of authors share?\n",
    "# how likely are 2 clusters share same journals?\n",
    "# comlexity is O(N^2)\n",
    "#@numba.jit\n",
    "def grpCmOneGram(d,feature='coauthor',type='avg'):\n",
    "    # d is a sub-dataframe contains n records\n",
    "    # feature is the feature you want to caculate overlapping\n",
    "    # type is one of {'avg','ratio'} rario is common number of records normalized by length of that feature(e.g. \n",
    "    #common co-author/#total co-author)\n",
    "    n = d.shape[0]\n",
    "    if len(d.shape)<2:\n",
    "        d = d.to_frame().transpose()\n",
    "        d = pd.concat([d,d])\n",
    "        n = 2\n",
    "    d = d[feature].tolist()\n",
    "    sum_grp = 0\n",
    "    for i in range(n-1):\n",
    "        for j in range((i+1),n):\n",
    "            this_pair = [d[i],d[j]]\n",
    "            cm_w = cmOneGram(this_pair)\n",
    "            sum_grp += cm_w\n",
    "    avg_grp = sum_grp/(comb(n,2)*1.0)\n",
    "    return avg_grp\n",
    "% timeit grpCmOneGram(df)\n",
    "grpCmOneGram(df)\n",
    "# cluster of records to a k-dim feature\n",
    "#@numba.jit\n",
    "def cluster2vec(d):\n",
    "    # d is a sub-dataframe contains n records\n",
    "    k1 = grpCmOneGram(d,'coauthor')\n",
    "    k2 = grpCmOneGram(d,'journalTitle')\n",
    "    return(np.array((k1,k2)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare 2 partitions\n",
    "## generate T0 partition matrix\n",
    "#@numba.jit\n",
    "def label2mat(t):\n",
    "    '''\n",
    "    input: t is a 1d-array of partition labels, shape is (n_records,), e.g. array([1,1,2,3])\n",
    "    output: m is a 2d-array adjacency matrix of shape (n_records,n_records)\n",
    "    '''\n",
    "    n = t.shape[0]\n",
    "    m = np.eye(n)\n",
    "    for i in range((n-1)):\n",
    "        for j in range((i+1),n):\n",
    "            if (t[j]==t[i]):\n",
    "                m[i,j] = 1\n",
    "    m += (m.transpose() - np.eye(n))\n",
    "    return(m)\n",
    "#@numba.jit\n",
    "def mat2label(m):\n",
    "    '''\n",
    "    input: m is a 2d-array adjacency matrix of shape (n_records,n_records)\n",
    "    output: t is a 1d-array of partition labels, shape is (n_records,), e.g. array([1,1,2,3])\n",
    "    '''\n",
    "    n = m.shape[0]\n",
    "    t = np.zeros(n)\n",
    "    k = 1\n",
    "    for i in range(n):\n",
    "        if (t[i]==0):\n",
    "            t[m[i,]==1] = k\n",
    "            k += 1\n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 56.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit mat2label(label2mat(my_df.label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## true score function\n",
    "def scoreTrue(t,t_star,vec=True):\n",
    "    '''\n",
    "    input: t,t_star are partitions of the dataframe, e.g. t = array([1,1,2,3,1])\n",
    "           vec is True use label2mat, otherwise use t\n",
    "    output: s is the precision of t based on ground truth t0\n",
    "    '''\n",
    "    if vec:\n",
    "        m = label2mat(t)\n",
    "        m_star = label2mat(t_star)\n",
    "        n = m.shape[0]\n",
    "        agree_pairs = np.sum(m==m_star)\n",
    "    else:\n",
    "        agree_pairs = 0\n",
    "        n = t.shape[0]\n",
    "        for i in range(n-1):\n",
    "            for j in range((i+1),n):\n",
    "                if (((t[i]==t[j])&(t_star[i]==t_star[j]))|((t[i]!=t[j])&(t_star[i]!=t_star[j]))):\n",
    "                    agree_pairs += 1\n",
    "    s = agree_pairs/(n*(n-1)*0.5)\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "#%prun -l 4 scoreTrue(my_df.label.values[:3],my_df.label.values[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 159 µs per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit scoreTrue(my_df.label.values[:15],my_df.label.values[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 160 µs per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit scoreTrue(my_df.label.values[:15],my_df.label.values[:15],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 22.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 72 µs per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit scoreTrue(my_df.label.values[:5],my_df.label.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.50 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 44 µs per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit scoreTrue(my_df.label.values[:5],my_df.label.values[:5],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## how much does precision increase after merging 2 clusters compared to before\n",
    "def c_scoreTrue(i,j,t,t_star):\n",
    "    '''\n",
    "    input: i,j are the i-th and j-th cluster label in a t-partition\n",
    "           t is the current partition, e.g. array([1,1,3,4,3])\n",
    "           t_star is the \n",
    "    output: s is the precision of the new partition after merging i-th and j-th clusters\n",
    "    '''\n",
    "    uni_t = np.unique(t)\n",
    "    new_t = np.copy(t)\n",
    "    ind = ((t==uni_t[j])|(t==uni_t[i]))\n",
    "    new_t[t==uni_t[j]] = uni_t[i]\n",
    "    sub_before = t[ind]\n",
    "    sub_after = new_t[ind]\n",
    "    sub_star = t_star[ind]\n",
    "    if (sum(ind)<=15):\n",
    "        s = (scoreTrue(sub_after,sub_star,False)-scoreTrue(sub_before,sub_star,False))\n",
    "    else:\n",
    "        s = (scoreTrue(sub_after,sub_star)-scoreTrue(sub_before,sub_star))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.05 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit c_scoreTrue(293,302,t,t_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateW(w,gw,gw_star,h=1):\n",
    "    '''\n",
    "    input: w is the weight parameter to be updated\n",
    "           gw is the similarity vector for algorithm predicted pair of clusters\n",
    "           gw_star is the similarity vector for true pair of clusters\n",
    "           h is the threshold for weighted similarity of our wrong choice of merged clusters\n",
    "    '''\n",
    "    alpha = 0.001\n",
    "    while((gw_star.dot(w)<gw.dot(w)+1)|(gw.dot(w)>h)):\n",
    "        w += (gw_star - gw)*alpha\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "i = 302\n",
    "j = 293\n",
    "t = np.array([i for i in range(my_df.shape[0])])\n",
    "X = my_df.ix[:,features].values\n",
    "uni_t = np.unique(t)\n",
    "gw = C_sml(X[t==uni_t[i],],X[t==uni_t[j],])\n",
    "gw_star = C_sml(X[t==uni_t[0],],X[t==uni_t[1],])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#print(gw_star.dot(w))\n",
    "#print(gw.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#updateW(w,gw,gw_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select a nearest pair of clusters and merge them\n",
    "def predMerge(t,X,w):\n",
    "    '''\n",
    "    input: t is a 1d-array of partition labels, shape is (n_record,)\n",
    "           X is a 2d-array of records values, not including label, shape is (n_records, n_feature)\n",
    "           w is a 1d-array of importance weight, shape is (n_feature,)\n",
    "           t_star is a 1d-array of true partition labels, shape is (n_record,)\n",
    "    output: best_t is the new partition which maximize the weighted average similarity between each pair of clusters\n",
    "    '''\n",
    "    uni_t = np.unique(t)\n",
    "    n_c = uni_t.shape[0]\n",
    "    #best_t = t\n",
    "    best_ind = [-1,-1]\n",
    "    max_score = -1\n",
    "    gw = np.zeros(w.shape)\n",
    "    for i in range(n_c-1):\n",
    "        for j in range((i+1),n_c):\n",
    "            this_sim = C_sml(X[t==uni_t[i],],X[t==uni_t[j],])\n",
    "            this_score = this_sim.dot(w)\n",
    "            if (this_score>max_score):\n",
    "                max_score = this_score\n",
    "                best_ind = [i,j]\n",
    "                gw = this_sim\n",
    "                #new_t = (t[t==uni_t[best_ind[1]]]=uni_t[best_ind[0]])\n",
    "                #if (scoreTrue(new_t,t_star)<scoreTrue(t,t_star)):\n",
    "                #    pass #update w\n",
    "    new_t = np.copy(t)\n",
    "    new_t[t==uni_t[best_ind[1]]] = uni_t[best_ind[0]]\n",
    "    #return(new_t)\n",
    "    return (best_ind,new_t,gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 13.8 s per loop\n"
     ]
    }
   ],
   "source": [
    "#t0 = np.array([i for i in range(my_df.shape[0])])\n",
    "#X = my_df.ix[:,features].values\n",
    "#%timeit predMerge(t0,X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(t0,X,w,R):\n",
    "    '''\n",
    "    input: t0 is the initial partition of shape (n_record,)\n",
    "           X is the 2-d array of record features, n_record*n_feature\n",
    "           w is the weight of shape (n_feature,)\n",
    "           R is the number of partitions in a sequence\n",
    "    output: T is a sequence of  partitions, T_merge is the predicted merge clusters index, G_W is a sequence \n",
    "    of gradience at w\n",
    "    '''\n",
    "    T = [t0]\n",
    "    T_merge = []\n",
    "    G_W = []\n",
    "    for r in range(R):\n",
    "        ind,t,gw = predMerge(T[r],X,w)\n",
    "        T.append(t)\n",
    "        T_merge.append(ind)\n",
    "        G_W.append(gw)\n",
    "        print(r)\n",
    "    return (T,T_merge,G_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#T = createTree(t0,X,w,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576,)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.unique(T[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trueMerge(t,X,t_star,best_ind,gw):\n",
    "    '''\n",
    "    input: t is the partition before merge\n",
    "           X is the data 2d-array\n",
    "           t_star is the ground truth partition\n",
    "           best_ind is the predicted best merge indexes\n",
    "           gw is the predicted gradience\n",
    "    output: best_ind is updated to the best merge indexes under true score, gw_star is the gradience \n",
    "    of true score at w\n",
    "    '''\n",
    "    uni_t = np.unique(t)\n",
    "    n_c = uni_t.shape[0]\n",
    "    max_score = c_scoreTrue(best_ind[0],best_ind[1],t,t_star)\n",
    "    gw_star = np.copy(gw)\n",
    "    #max_score = scoreTrue(t_1,t_star)\n",
    "    #best_t = np.copy(t)\n",
    "    #best_ind = [-1,-1]\n",
    "    #max_score = -1\n",
    "    for i in range(n_c-1):\n",
    "        for j in range((i+1),n_c):\n",
    "            this_sim = C_sml(X[t==uni_t[i],],X[t==uni_t[j],])\n",
    "            #this_t = np.copy(t)\n",
    "            #this_t[t==uni_t[j]] = uni_t[i]\n",
    "            this_score = c_scoreTrue(i,j,t,t_star)\n",
    "            #this_score = scoreTrue(this_t,t_star)\n",
    "            if (this_score>max_score):\n",
    "                max_score = this_score\n",
    "                best_ind = [i,j]\n",
    "                gw_star = this_sim\n",
    "                #best_t = this_t\n",
    "                break\n",
    "    return (best_ind,gw_star)\n",
    "    #return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[293, 302]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trueMerge(T[0],X,t_star,[293,302])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "#% prun -l 4 trueMerge(t,X,t_star,[293,302])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# update parameters\n",
    "## when an error occurs\n",
    "# select a nearest pair of clusters and merge them\n",
    "def inner_predMerge(t,X,w):\n",
    "    '''\n",
    "    '''\n",
    "    input: t is a 1d-array of partition labels, shape is (n_record,)\n",
    "           X is a 2d-array of records values, not including label, shape is (n_records, n_feature)\n",
    "           w is a 1d-array of importance weight, shape is (n_feature,)\n",
    "           t_star is a 1d-array of true partition labels, shape is (n_record,)\n",
    "    output: best_t is the new partition which maximize the weighted average similarity between each pair of clusters\n",
    "    '''\n",
    "    '''\n",
    "    uni_t = np.unique(t)\n",
    "    n_c = uni_t.shape[0]\n",
    "    #best_t = t\n",
    "    best_ind = [-1,-1]\n",
    "    max_score = -1\n",
    "    for i in range(n_c):\n",
    "        for j in range((i+1),n_c):\n",
    "            this_sim = C_similarity(X[((t==uni_t[i])|(t==uni_t[j])),])\n",
    "            this_score = this_sim.dot(w)\n",
    "            if (this_score>max_score):\n",
    "                max_score = this_score\n",
    "                best_ind = [i,j]\n",
    "                #new_t = (t[t==uni_t[best_ind[1]]]=uni_t[best_ind[0]])\n",
    "                #if (scoreTrue(new_t,t_star)<scoreTrue(t,t_star)):\n",
    "                #    pass #update w\n",
    "    new_t = np.copy(t)\n",
    "    new_t[t==uni_t[best_ind[1]]] = uni_t[best_ind[0]]\n",
    "    #return(new_t)\n",
    "    return (best_ind,new_t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 15.4 s per loop\n"
     ]
    }
   ],
   "source": [
    "#%timeit inner_predMerge(t0,X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training\n",
    "# time complexity seems too high...\n",
    "def train_errorDriven(my_df,features,n_run=100,R=500,th=0.00001):\n",
    "    '''\n",
    "    input: my_df the cleaned-up dataframe\n",
    "           features is a list of features to be caculated\n",
    "           n_run is the number of iterations\n",
    "           R is the deepth of partition tree\n",
    "           th is the converge threshold\n",
    "    output: w0 is the best weight for similarity\n",
    "    '''\n",
    "    X = my_df.ix[:,features].values\n",
    "    t_star = my_df['label'].values\n",
    "    t0 = np.array([i for i in range(t_star.shape[0])])\n",
    "    w0 = np.random.uniform(size=(1,len(features)))\n",
    "\n",
    "    for i in range(n_run):\n",
    "        w = np.copy(w0)\n",
    "        T,T_merge,G_W = createTree(t0,X,w,R)\n",
    "        for i in range(len(T)-1):\n",
    "            true_merge,gw_star = trueMerge(T[i],X,t_star,T_merge[i],G_W[i])\n",
    "            if (true_merge!=T_merge[i]):\n",
    "                w0 = updateW(w,G_W[i],gw_star)\n",
    "                break\n",
    "            \n",
    "        if ((w-w0)^2<th):\n",
    "            break\n",
    "    return w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
