# The row and column position of the most common pair is stored as sequence m in the merge object
merge[m,] <- as.numeric(cols[d])
# The pair with the minimum distance(most coauthors) is merged
# The cluster object is used to find previous clusters that the pair belong to (if they exist)
# Does this by finding any columns above 0 (since all column names are negative, a positive column value implies it has been clustered)
cluster <- c(d, which(cols %in% cols[d[1, cols[d] > 0]]))
colnames(Lm)[cluster] <- m # Rename the columns indicated by cluster to the sequence number, m
# Merge the pairs according to single linkage method
sl <- apply(Lm[d,], 2, min)
# Remove column and row corresponding to old clusters and insert a new column and row for newly formed cluster.
# The insertion of the cluster is done by setting the first sequential row and column of the minimum pair in the distance matrix (top to bottom, left to right) as the cluster resulting from the single linkage step
Lm[min(d),] <- sl
Lm[,min(d)] <- sl
# Make sure the minimum distance pair is not used again by setting it to Inf
Lm[min(d), min(d)] <- Inf
# The removal step is done by setting the second sequential row and column of the minimum pair
# (farthest right, farthest down) to Inf
Lm[max(d),] <- Inf
Lm[,max(d)] <- Inf
}
}
a <- list(colnames(Lm))
return(a)
}
singlecluster(df)
table(singlecluster(df))
splitcluster(singlecluster(df))
singlecluster <- function(df){
n <- nrow(df)
# a matrix of the number of same coauthors
ssim <- matrix(rep(NA,n*n),ncol=n)
for (i in 1:n){
for (j in 1:n){
lengthi <- length(unlist(df[[5]][i]))
lengthj <- length(unlist(df[[5]][j]))
if (lengthi >0 & lengthj >0 ){
aaa <- matrix(0,nrow=lengthi,ncol=lengthj)
for (a in 1:lengthi){
for (b in 1:lengthj){
aaa[a,b] <- ifelse((df[[5]][[i]][a] ==   df[[5]][[j]][b]),aaa[a,b]+1,aaa[a,b])
# ssim[i,j] <- sum(aaa)
}
}
ssim[i,j] <- sum(aaa)
}
}
}
Lm <- as.data.frame(ssim*(-1))
Lm[is.na(Lm)] <- 0
N <- nrow(Lm)
merge <- matrix(0, N-1, 2)
height <- vector(length = N-1)
diag(Lm) <- Inf
colnames(Lm) <- -(1:N)
rownames(Lm) <- -(1:N)
for (m in 1:(N-1)) {
cols <- colnames(Lm)
# Find the pair with the most common coauthors
# The which() function returns the row and column position of the pair
d <- which(Lm == min(Lm), arr.ind = TRUE)[1,,drop=FALSE]
if (min(Lm) <= (-1)){
height[m] <- min(Lm) # The height is the value of the pair with the most common coauthors
# The row and column position of the most common pair is stored as sequence m in the merge object
merge[m,] <- as.numeric(cols[d])
# The pair with the minimum distance(most coauthors) is merged
# The cluster object is used to find previous clusters that the pair belong to (if they exist)
# Does this by finding any columns above 0 (since all column names are negative, a positive column value implies it has been clustered)
cluster <- c(d, which(cols %in% cols[d[1, cols[d] > 0]]))
colnames(Lm)[cluster] <- m # Rename the columns indicated by cluster to the sequence number, m
# Merge the pairs according to single linkage method
sl <- apply(Lm[d,], 2, min)
# Remove column and row corresponding to old clusters and insert a new column and row for newly formed cluster.
# The insertion of the cluster is done by setting the first sequential row and column of the minimum pair in the distance matrix (top to bottom, left to right) as the cluster resulting from the single linkage step
Lm[min(d),] <- sl
Lm[,min(d)] <- sl
# Make sure the minimum distance pair is not used again by setting it to Inf
Lm[min(d), min(d)] <- Inf
# The removal step is done by setting the second sequential row and column of the minimum pair
# (farthest right, farthest down) to Inf
Lm[max(d),] <- Inf
Lm[,max(d)] <- Inf
}
}
a <- colnames(Lm)
return(a)
}
splitcluster(singlecluster(df))
source("evaluation_measures.R")
getwd()
source("../lib/evaluation_measures.R")
a <- splitcluster(singlecluster(df))
df[[1]]
matching_matrix(a,df$authorNum)
matching_matrix(df$authorNum,a)
resultmatrix <- matching_matrix(a,df$authorNum)
performance_statistics(resultmatrix)
1544/(1544+4798)
1544/(1544+2190)
precision <- 1544/(1544+4798)
recall <- 1544/(1544+2190)
f1 <- 2*precision*recall/(precision+recall)
accuracy <- (1544+21114)/(1544+2190+4798+21114)
View(df)
View(a)
df <- cbind(a,df)
View(df)
df <- data[[2]]
a <- singlecluster(df)
table(a)
View(df)
abc <- as.data.frame(a)
View(abc)
abc <- as.data.frame(table(a))
View(abc)
abc <- abc[order(abc$Freq,decreasing = T),]
View(abc)
n <- length(a)
ncluster <- nrow(abc)
which(a==abc$a[1])
abc$a
View(abc)
# combine all singl-element cluster into one cluster
comninecluster <- function(df){
abc <- as.data.frame(table(df))
abc <- abc[order(abc$Freq,decreasing = T),]
n <- length(df)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (df$Freq > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
return(cluster.result)
}
}
# combine all singl-element cluster into one cluster
comninecluster <- function(df){
abc <- as.data.frame(table(df))
abc <- abc[order(abc$Freq,decreasing = T),]
n <- length(df)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (df$Freq > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
return(cluster.result)
}
comninecluster(a)
table(a)
aa <- as.data.frame(a)
table(aa)
comninecluster(aa)
table(aa)
as.data.frame(table(aa))
# combine all singl-element cluster into one cluster
comninecluster <- function(df){
abc <- as.data.frame(table(df))
abc <- abc[order(abc$Freq,decreasing = T),]
n <- length(df)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (df$Freq[i] > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
return(cluster.result)
}
comninecluster(aa)
abc <- as.data.frame(table(aa))
abc <- abc[order(abc$Freq,decreasing = T),]
View(abc)
length(aa)
nrow(aa)
# combine all singl-element cluster into one cluster
comninecluster <- function(df){
abc <- as.data.frame(table(df))
abc <- abc[order(abc$Freq,decreasing = T),]
n <- nrow(df)
# n <- length(df)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (df$Freq[i] > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
return(cluster.result)
}
nrow(abc)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (df$Freq[i] > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
View(aa)
aa <- as.data.frame(table(a))
View(aa)
# combine all singl-element cluster into one cluster
comninecluster <- function(df){
abc <- as.data.frame(table(df))
abc <- abc[order(abc$Freq,decreasing = T),]
n <- nrow(df)
# n <- length(df)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (abc$Freq[i] > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
return(cluster.result)
}
comninecluster(a)
# combine all singl-element cluster into one cluster
comninecluster <- function(df){
abc <- as.data.frame(table(df))
abc <- abc[order(abc$Freq,decreasing = T),]
# n <- nrow(df)
n <- length(df)
ncluster <- nrow(abc)
cluster.result <- matrix(0,nrow=n,ncol=1)
for (i in 1:ncluster){
if (abc$Freq[i] > 1){
a <- which(df==abc$df[i])
cluster.result[a] <- i
}
else{
cluster.result[a] <- 0
}
}
return(cluster.result)
}
comninecluster(a)
abcd <- comninecluster(a)
resultmatrix <- matching_matrix(df$authorNum,abcd)
performance_statistics(resultmatrix)
resultmatrix
max(abcd)
precision <- 5305/(5305+1281)
recall <- 5305/(5305+14691)
f1 <- 2*precision*recall/(precision+recall)
f1
(5305+8613)/(14691+8613+5305+8613)
cbind(abcd,df)
View(df)
dff <- cbind(abcd,df)
View(dff)
df[[5]][112]
df[[5]][131]
df[[5]][[131]][1]
df[[5]][[112]][1]
df[[5]][[112]][1]==df[[5]][[131]][1]
df[[5]][[112]][1][is.na(df[[5]][[112]][1])]
is.na(df[[5]][[112]][1])
is.na(df[[5]][[131]][1])
singlecluster <- function(df){
n <- nrow(df)
# a matrix of the number of same coauthors
ssim <- matrix(rep(NA,n*n),ncol=n)
for (i in 1:n){
for (j in 1:n){
lengthi <- length(unlist(df[[5]][i]))
lengthj <- length(unlist(df[[5]][j]))
if (lengthi >0 & lengthj >0 ){
aaa <- matrix(0,nrow=lengthi,ncol=lengthj)
for (a in 1:lengthi){
for (b in 1:lengthj){
aaa[a,b] <- ifelse((df[[5]][[i]][a] ==   df[[5]][[j]][b]),aaa[a,b]+1,aaa[a,b])
# ssim[i,j] <- sum(aaa)
}
}
ssim[i,j] <- sum(aaa)
}
}
}
Lm <- as.data.frame(ssim*(-1))
Lm[is.na(Lm)] <- 0
N <- nrow(Lm)
merge <- matrix(0, N-1, 2)
height <- vector(length = N-1)
diag(Lm) <- Inf
colnames(Lm) <- -(1:N)
rownames(Lm) <- -(1:N)
for (m in 1:(N-1)) {
cols <- colnames(Lm)
# Find the pair with the most common coauthors
# The which() function returns the row and column position of the pair
d <- which(Lm == min(Lm), arr.ind = TRUE)[1,,drop=FALSE]
if (min(Lm) <= (-2)){
height[m] <- min(Lm) # The height is the value of the pair with the most common coauthors
# The row and column position of the most common pair is stored as sequence m in the merge object
merge[m,] <- as.numeric(cols[d])
# The pair with the minimum distance(most coauthors) is merged
# The cluster object is used to find previous clusters that the pair belong to (if they exist)
# Does this by finding any columns above 0 (since all column names are negative, a positive column value implies it has been clustered)
cluster <- c(d, which(cols %in% cols[d[1, cols[d] > 0]]))
colnames(Lm)[cluster] <- m # Rename the columns indicated by cluster to the sequence number, m
# Merge the pairs according to single linkage method
sl <- apply(Lm[d,], 2, min)
# Remove column and row corresponding to old clusters and insert a new column and row for newly formed cluster.
# The insertion of the cluster is done by setting the first sequential row and column of the minimum pair in the distance matrix (top to bottom, left to right) as the cluster resulting from the single linkage step
Lm[min(d),] <- sl
Lm[,min(d)] <- sl
# Make sure the minimum distance pair is not used again by setting it to Inf
Lm[min(d), min(d)] <- Inf
# The removal step is done by setting the second sequential row and column of the minimum pair
# (farthest right, farthest down) to Inf
Lm[max(d),] <- Inf
Lm[,max(d)] <- Inf
}
}
a <- colnames(Lm)
return(a)
}
singlecluster(df)
a <- singlecluster(df)
aa <- splitcluster(a)
resultmatrix <- matching_matrix(df$authorNum,aa)
resultmatrix
performance_statistics(resultmatrix)
abcd <- comninecluster(a)
resultmatrix <- matching_matrix(df$authorNum,a)
resultmatrix
performance_statistics(resultmatrix)
abcd <- comninecluster(a)
resultmatrix <- matching_matrix(df$authorNum,abcd)
resultmatrix
performance_statistics(resultmatrix)
singlecluster <- function(df){
n <- nrow(df)
# a matrix of the number of same coauthors
ssim <- matrix(rep(NA,n*n),ncol=n)
for (i in 1:n){
for (j in 1:n){
lengthi <- length(unlist(df[[5]][i]))
lengthj <- length(unlist(df[[5]][j]))
if (lengthi >0 & lengthj >0 ){
aaa <- matrix(0,nrow=lengthi,ncol=lengthj)
for (a in 1:lengthi){
for (b in 1:lengthj){
aaa[a,b] <- ifelse((df[[5]][[i]][a] ==   df[[5]][[j]][b]),aaa[a,b]+1,aaa[a,b])
# ssim[i,j] <- sum(aaa)
}
}
ssim[i,j] <- sum(aaa)
}
}
}
Lm <- as.data.frame(ssim*(-1))
Lm[is.na(Lm)] <- 0
N <- nrow(Lm)
merge <- matrix(0, N-1, 2)
height <- vector(length = N-1)
diag(Lm) <- Inf
colnames(Lm) <- -(1:N)
rownames(Lm) <- -(1:N)
for (m in 1:(N-1)) {
cols <- colnames(Lm)
# Find the pair with the most common coauthors
# The which() function returns the row and column position of the pair
d <- which(Lm == min(Lm), arr.ind = TRUE)[1,,drop=FALSE]
if (min(Lm) <= (-1)){
height[m] <- min(Lm) # The height is the value of the pair with the most common coauthors
# The row and column position of the most common pair is stored as sequence m in the merge object
merge[m,] <- as.numeric(cols[d])
# The pair with the minimum distance(most coauthors) is merged
# The cluster object is used to find previous clusters that the pair belong to (if they exist)
# Does this by finding any columns above 0 (since all column names are negative, a positive column value implies it has been clustered)
cluster <- c(d, which(cols %in% cols[d[1, cols[d] > 0]]))
colnames(Lm)[cluster] <- m # Rename the columns indicated by cluster to the sequence number, m
# Merge the pairs according to single linkage method
sl <- apply(Lm[d,], 2, min)
# Remove column and row corresponding to old clusters and insert a new column and row for newly formed cluster.
# The insertion of the cluster is done by setting the first sequential row and column of the minimum pair in the distance matrix (top to bottom, left to right) as the cluster resulting from the single linkage step
Lm[min(d),] <- sl
Lm[,min(d)] <- sl
# Make sure the minimum distance pair is not used again by setting it to Inf
Lm[min(d), min(d)] <- Inf
# The removal step is done by setting the second sequential row and column of the minimum pair
# (farthest right, farthest down) to Inf
Lm[max(d),] <- Inf
Lm[,max(d)] <- Inf
}
}
a <- colnames(Lm)
return(a)
}
source("../lib/evaluation_measures.R")
a <- singlecluster(df)
aa <- splitcluster(a)
resultmatrix <- matching_matrix(df$authorNum,aa)
resultmatrix
performance_statistics(resultmatrix)
abcd <- comninecluster(a)
resultmatrix <- matching_matrix(df$authorNum,abcd)
resultmatrix
performance_statistics(resultmatrix)
source("../lib/evaluation_measures.R")
abcd <- comninecluster(a)
resultmatrix <- matching_matrix(df$authorNum,abcd)
resultmatrix
performance_statistics(resultmatrix)
clustering_errors(resultmatrix)
load("../data/data.RData")
load("../data/data.RData")
getwd
getwd()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Users/yuxin/Spr2017-proj4-team-11/data")
load("../data/data.RData")
library(stringr)
data.lib="../data/nameset/"
data.files=list.files(pattern = ".*txt")
data.lib="../nameset/"
data.files=list.files(pattern = ".*txt")
setwd("~/Spr2017-proj4-team-11/doc")
library(stringr)
data.lib="../data/nameset/"
data.files=list.files(pattern = ".*txt")
data.files
setwd("~/Spr2017-proj4-team-11/data")
data.lib="../nameset/"
data.files=list.files(pattern = ".*txt")
data.files=list.files(pattern = ".*txt")
data.lib="../nameset/"
data.files=list.files(pattern = ".*txt")
setwd("~/Spr2017-proj4-team-11/data/nameset")
data.files=list.files(pattern = ".*txt")
setwd("~/Spr2017-proj4-team-11/data")
data.lib="~/nameset/"
data.files=list.files(pattern = ".*txt")
data.lib="~/nameset"
data.files=list.files(pattern = ".*txt")
data.lib="~/data/nameset"
data.files=list.files(pattern = ".*txt")
setwd("~/Spr2017-proj4-team-11/data/nameset")
data.lib="~/data/nameset"
data.files=list.files(pattern = ".*txt")
setwd("~/Users/yuxin/Spr2017-proj4-team-11/data")
setwd("~/Users/yuxin/Spr2017-proj4-team-11/data")
setwd("~/Spr2017-proj4-team-11/doc")
source("../lib/dataclean.R")
source("../lib/Data Process.R")
source("../lib/Data PreProcess.R")
source("../lib/Data Preprocess.R")
source("../lib/Data Preprocess.R")
source("Data Preprocess.R")
source("../Data Preprocess.R")
source("../lib/dataclean.R")
load("../data/data.RData")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Spr2017-proj4-team-11/doc")
source("../lib/dataclean.R")
load("../data/data.RData")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Spr2017-proj4-team-11/doc")
data.lib="~/data/nameset"
data.files=list.files(pattern = ".*txt")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Spr2017-proj4-team-11/doc")
data.lib="../data/nameset"
data.files=list.files(pattern = ".*txt")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Spr2017-proj4-team-11/doc")
source("../lib/dataclean.R")
load("../data/data.RData")
source("../lib/dataclean.R")
data.files=list.files(pattern = ".*txt")
data.lib="../data/nameset"
data.files=list.files(path=data.lib,pattern = ".*txt")
source("../lib/dataclean.R")
load("../data/data.RData")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
setwd("~/Spr2017-proj4-team-11/doc")
source("../lib/dataclean.R")
load("../data/data.RData")
