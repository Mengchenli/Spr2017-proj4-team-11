2*precition*recall/(precision+recall)
2*precision*recall/(precision+recall)
recall
precision
matching_matrix <- function(G,M){
n <- length(G)
result_matrix <- matrix(rep(0,4),ncol=2,nrow=2)
for(i in 1:(n-1)){
for(j in (i+1):n){
if(G[i]==G[j]&M[i]==M[j]) result_matrix[1,1]<-result_matrix[1,1]+1
if(G[i]!=G[j]&M[i]==M[j]) result_matrix[1,2]<-result_matrix[1,2]+1
if(G[i]==G[j]&M[i]!=M[j]) result_matrix[2,1]<-result_matrix[2,1]+1
if(G[i]!=G[j]&M[i]!=M[j]) result_matrix[2,2]<-result_matrix[2,2]+1
}
}
return(result_matrix)
}
result_matrix <- matching_matrix(AKumar$AuthorID,group.14)
result_matrix
(761+20383)/n
n
nrow(dtm_train)
(761+20383)/(n*(n-1)/2)
sum(result_matrix)
n*(n-1)/2
length(unique(AKumar$AuthorID))
result_hclust <- cutree(h,length(unique(AKumar$AuthorID)))
table(result_hclust)
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
performance_statistics <- function(result_matrix){
precision <- result_matrix[1,1]/(result_matrix[1,1]+result_matrix[1,2])
recall <- result_matrix[1,1]/(result_matrix[1,1]+result_matrix[2,1])
f1 <- 2*precision*recall/(precision+recall)
accuracy <- (result_matrix[1,1]+result_matrix[2,2])/sum(result_matrix)
}
performance_hclust <- performance_statistics(matching_matrix_hclust)
performance_hclust
performance_statistics <- function(result_matrix){
precision <- result_matrix[1,1]/(result_matrix[1,1]+result_matrix[1,2])
recall <- result_matrix[1,1]/(result_matrix[1,1]+result_matrix[2,1])
f1 <- 2*precision*recall/(precision+recall)
accuracy <- (result_matrix[1,1]+result_matrix[2,2])/sum(result_matrix)
return(list(precision=precision, recall=recall, f1=f1, accuracy=accuracy))
}
performance_hclust <- performance_statistics(matching_matrix_hclust)
performance_hclust
setwd("./Project4_WhoIsWho")
setwd("~/Dropbox/Project4_WhoIsWho")
setwd("~/Dropbox/Project4_WhoIsWho")
AKumar <- data.frame(scan("~/Dropbox/Project4_WhoIsWho/data/nameset/AKumar.txt",
what = list(Coauthor = "", Paper = "", Journal = ""), sep=">", quiet=TRUE),stringsAsFactors=FALSE)
source('~/Dropbox/Project4_WhoIsWho/lib/evaluation_measures.R')
vocab <- create_vocabulary(it_train)
vocab
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
n <- nrow(dtm_train)
cmb <- expand.grid(i=1:n, j=1:n)
docsdissim <- as.dist(matrix(apply(cmb,1,cos.sim),n,n))
rownames(docsdissim) <- c(1:n)
colnames(docsdissim) <- c(1:n)
h <- hclust(docsdissim, method = "ward.D")
n
dim(docsdissim)
h <- hclust(docsdissim, method = "ward.D")
plot(h, labels = c(1:n), sub = "")
result_hclust <- cutree(h,length(unique(AKumar$AuthorID)))
length(unique(AKumar$AuthorID))
unique(AKumar$AuthorID)
setwd("~/Dropbox/Project4_WhoIsWho/doc")
AKumar <- data.frame(scan("~/Dropbox/Project4_WhoIsWho/data/nameset/AKumar.txt",
what = list(Coauthor = "", Paper = "", Journal = ""),
sep=">", quiet=TRUE),stringsAsFactors=FALSE)
# This need to be modified for different name set
# extract canonical author id befor "_"
AKumar$AuthorID <- sub("_.*","",AKumar$Coauthor)
# extract paper number under same author between "_" and first whitespace
AKumar$PaperNO <- sub(".*_(\\w*)\\s.*", "\\1", AKumar$Coauthor)
# delete "<" in AKumar$Coauthor, you may need to further process the coauthor
# term depending on the method you are using
AKumar$Coauthor <- gsub("<","",sub("^.*?\\s","", AKumar$Coauthor))
# delete "<" in AKumar$Paper
AKumar$Paper <- gsub("<","",AKumar$Paper)
# add PaperID for furthur use, you may want to combine all the nameset files and
# then assign the unique ID for all the citations
AKumar$PaperID <- rownames(AKumar)
it_train <- itoken(AKumar$Paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
ids = AKumar$PaperID,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
vocab <- create_vocabulary(it_train)
vocab
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
cos.sim <- function(ix)
{
A = dtm_train[ix[1],]
B = dtm_train[ix[2],]
return( sum(A*B)/sqrt(sum(A^2)*sum(B^2)) )
}
n <- nrow(dtm_train)
cmb <- expand.grid(i=1:n, j=1:n)
docsdissim <- as.dist(matrix(apply(cmb,1,cos.sim),n,n))
rownames(docsdissim) <- c(1:n)
h <- hclust(docsdissim, method = "ward.D")
plot(h, labels = c(1:n), sub = "")
result_hclust <- cutree(h,length(unique(AKumar$AuthorID)))
table(result_hclust)
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
performance_hclust
vocab <- create_vocabulary(it_train, stopwords = c("a", "the", "in", "on", "at", "above", "under"))
vocab
vocab <- prune_vocabulary(vocab,
term_count_min = 1
doc_proportion_max = 0.95,
doc_proportion_min = 0.001)
vocab <- prune_vocabulary(vocab,
term_count_min = 1,
doc_proportion_max = 0.95,
doc_proportion_min = 0.001)
vocab
26+14+61+15+100+16+12+31+10+13+13+12+86+71
577+244+800+368+1417+112+171+927+280+153+259+412+1458+1264
dtm_train_tfidf[1:10,1:10]
dtm_train_tfidf[10:20,10:20]
dtm_train_tfidf[1:20,10:20]
dtm_train[1:20,10:20]
cos.sim <- function(ix)
{
A = dtm_train_tfidf[ix[1],]
B = dtm_train_tfidf[ix[2],]
return( sum(A*B)/sqrt(sum(A^2)*sum(B^2)) )
}
n <- nrow(dtm_train)
cmb <- expand.grid(i=1:n, j=1:n)
docsdissim <- as.dist(matrix(apply(cmb,1,cos.sim),n,n))
h <- hclust(docsdissim, method = "ward.D")
plot(h, labels = c(1:n), sub = "")
result_hclust <- cutree(h,length(unique(AKumar$AuthorID)))
table(result_hclust)
source('~/Dropbox/Project4_WhoIsWho/lib/evaluation_measures.R')
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
performance_hclust
View(AKumar)
my.data
data(UScitiesD)
mds2 <- -cmdscale(UScitiesD)
plot(mds2, type="n", axes=FALSE, ann=FALSE)
text(mds2, labels=rownames(mds2), xpd = NA)
UScitiesD
hcity.D  <- hclust(UScitiesD, "ward.D") # "wrong"
hcity.D2 <- hclust(UScitiesD, "ward.D2")
opar <- par(mfrow = c(1, 2))
plot(hcity.D,  hang=-1)
plot(hcity.D2, hang=-1)
require(graphics)
USArrests
dist(USArrests)
dist(USArrests)[1,1]
class(dist(USArrests))
?dist
as.matrix(dist(USArrests))[1,2]
USArrests[1,]
USArrests[2,]
dist(USArrests[1,],USArrests[2,])
USArrests[1,]%*%USArrests[2,]
t(USArrests[1,])%*%USArrests[2,]
t(as.vector(USArrests[1,]))%*%as.vector(USArrests[2,])
class(USArrests[2,])
as.vector(USArrests[2,])
USArrests[1,]
10*13.2+263*236+48*58+44.5*21.2
sqrt(65927.4)
as.matrix(dist(USArrests))[1,1]
3.2^2+27^2+100+(44.5-21.2)^2
sqrt(1382.13)
pacman::p_load(text2vec, dplyr, qlcMatrix)
dim(cosSparse(dtm_train_tfidf))
n
dim(dtm_train_tfidf)
class(dtm_train_tfidf)
dim(cosSparse(t(dtm_train_tfidf)))
nrow(dtm_train_tfidf)
docsdissim <- cosSparse(t(dtm_train_tfidf))
rownames(docsdissim) <- c(1:nrow(dtm_train_tfidf))
colnames(docsdissim) <- c(1:nrow(dtm_train_tfidf))
#compute pairwise cosine similarities between citations, using cosSparse function in package
h <- hclust(as.dist(docsdissim), method = "ward")
h <- hclust(as.dist(docsdissim), method = "ward.D")
result_hclust <- cutree(h,length(unique(AKumar$AuthorID)))
table(result_hclust)
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
performance_hclust
result_hclust <- specc(dtm_train_tfidf, centers=length(unique(AKumar$AuthorID)))
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab)
result_hclust <- specc(dtm_train_tfidf, centers=length(unique(AKumar$AuthorID)))
result_hclust <- specc(as.matrix(dtm_train_tfidf), centers=length(unique(AKumar$AuthorID)))
```
result_hclust <- specc(as.matrix(dtm_train_tfidf), centers=length(unique(AKumar$AuthorID)))
result_sclust <- specc(as.matrix(dtm_train_tfidf), centers=length(unique(AKumar$AuthorID)))
table(result_sclust)
matching_matrix_sclust <- matching_matrix(AKumar$AuthorID,result_sclust)
performance_sclust <- performance_statistics(matching_matrix_sclust)
performance_sclust
performance_hclust
?table
start.time <- Sys.time()
result_sclust <- specc(as.matrix(dtm_train_tfidf), centers=length(unique(AKumar$AuthorID)))
end.time <- Sys.time()
time_sclust <- end.time - start.time
time_sclust
start.time <- Sys.time()
docsdissim <- cosSparse(t(dtm_train_tfidf))
rownames(docsdissim) <- c(1:nrow(dtm_train_tfidf))
colnames(docsdissim) <- c(1:nrow(dtm_train_tfidf))
#compute pairwise cosine similarities between citations, using cosSparse function in package
h <- hclust(as.dist(docsdissim), method = "ward.D")
result_hclust <- cutree(h,length(unique(AKumar$AuthorID)))
end.time <- Sys.time()
time_hclust <- end.time - start.time
time_hclust
performance_sclust
source('~/Dropbox/Project4_WhoIsWho/lib/evaluation_measures.R')
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
matching_matrix_sclust <- matching_matrix(AKumar$AuthorID,result_sclust)
performance_sclust <- performance_statistics(matching_matrix_sclust)
compare_df <- data.frame(method=c(sClust,hClust),
precision=c(performance_sclust$precision, performance_hclust$precision),
recall=c(performance_sclust$recall, performance_hclust$recall),
f1=c(performance_sclust$f1, performance_hclust$f1),
accuracy=c(performance_sclust$accuracy, performance_hclust$accuracy),
time=c(time_sclust,time_hclust))
kable(compare_df,caption="Comparision of performance for two clustering methods",digits = 2)
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
matching_matrix_sclust <- matching_matrix(AKumar$AuthorID,result_sclust)
performance_sclust <- performance_statistics(matching_matrix_sclust)
compare_df <- data.frame(method=c("sClust","hClust"),
precision=c(performance_sclust$precision, performance_hclust$precision),
recall=c(performance_sclust$recall, performance_hclust$recall),
f1=c(performance_sclust$f1, performance_hclust$f1),
accuracy=c(performance_sclust$accuracy, performance_hclust$accuracy),
time=c(time_sclust,time_hclust))
kable(compare_df,caption="Comparision of performance for two clustering methods",digits = 2)
end.time - start.time
load("C:/Users/Brown/Documents/GitHub/Spr2017-proj4-team-11/data/profclean.RData")
AG <- data_list[[1]]
AG_df <- data.frame(NA)
View(AG_df)
for (i in length(AG)) {}
length(AG)
length(unlist(AG[1]))
length(unlist(AG[[1]]))
AG[[1]]
length(AG[[1]])
for (i in length(AG)){
for (j in length(AG[[1]])){
AG_df[i,j] <- AG[[i]][[j]]
}
}
length(AG[[1]])
for (i in length(AG)){
for (j in length(AG[[i]])){
AG_df[i,j] <- AG[[i]][[j]]
}
}
AG[[1]][[3]]
for (i in 1:length(AG)){
for (j in 1:length(AG[[i]])){
AG_df[i,j] <- AG[[i]][[j]]
}
}
View(AG_df)
length(list1)
list1 <- data_list[[1]]
length(list1)
?lapply
list1[[1]]
list1[[1]][5]
load("C:/Users/Lloyd/Documents/GitHub/Spr2017-proj4-team-11/data/profclean.RData")
load("../data/profclean.RData")
length(list1)
list1 <- data_list[[1]]
length(list1)
list1 <- data_list[[1]]
num_t1 <- 200
for (i in 1:length(list1)) {
list1[[i]][6] <- sample(1:2, 577, prob = c(200/577, 377/577), replace = TRUE)
}
warnings()
list1[[577]]
data_list[[1]]
data_list[[1]][[1]][1]
data_list[[1]][[1]][[1]]
data_list[[1]][[1]][[3]]
data_list[[1]][[1]][3
]
str(data_list[[1]][[1]][3])
str(data_list[[1]][[1]][1])
getcol <- function(datalist, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(datalist[[listNum]])) {
col[i] <- unlist(datalist[[listNum]][[colNum]][[i]])
}
}
getcol(data_list, 1, 1)
data_list[[1]][[1]][1]
unlist(data_list[[1]][[1]][1])
str(unlist(data_list[[1]][[1]][1]))
getcol <- function(datalist, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(datalist[[listNum]])) {
col[i] <- unlist(datalist[[listNum]][[colNum]][[i]])
}
return(col)
}
getcol(data_list, 1, 1)
col <- rep(NA)
for (i in 1:length(datalist[[1]])) {
col[i] <- unlist(datalist[[1]][[1]][[i]])
}
col <- rep(NA)
for (i in 1:length(data_list[[1]])) {
col[i] <- unlist(data_list[[1]][[1]][[i]])
}
data_list[[1]][[1]][[1]]
data_list[[1]][[1]][[2]]
getcol <- function(datalist = data_list, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(datalist[[listNum]])) {
col[i] <- unlist(datalist[[listNum]][[i]][[colNum]])
}
return(col)
}
getcol(1,1)
data_list[[1]][[2]][[1]]
data_list[[1]][[3]][[1]]
data_list[[1]][[11]][[1]]
data_list[[1]][[12]][[1]]
col <- rep(NA)
for (i in 1:length(data_list[[listNum]])) {
col[i] <- unlist(data_list[[listNum]][[i]][[colNum]])
}
col <- rep(NA)
for (i in 1:length(data_list[[1]])) {
col[i] <- unlist(data_list[[1]][[i]][[1]])
}
getcol <- function(data_list = data_list, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(data_list[[listNum]])) {
col[i] <- unlist(data_list[[listNum]][[i]][[colNum]])
}
return(col)
}
getcol(1, 1)
getcol(listNum = 1, colNum = 1)
getcol(data_list, listNum = 1, colNum = 1)
getcol <- function(datalist, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(datalist[[listNum]])) {
col[i] <- unlist(datalist[[listNum]][[i]][[colNum]])
}
return(col)
}
head(getcol(data_list,1,1))
head(getcol(data_list,1,2))
head(getcol(data_list,1,3))
datalist[[1]][[i]][[3]]
data_list[[1]][[i]][[3]]
data_list[[1]][[1]][[3]]
str(data_list[[1]][[1]][[3]])
head(getcol(data_list, 1, 4))
head(getcol(data_list, 1, 5))
getcolaslist <- function(datalist, listNum, colNum) {
col <- list(NA)
for (i in 1:length(datalist[[listNum]])) {
col[i] <- datalist[[listNum]][[i]][[colNum]]
}
return(col)
}
getcolaslist(data_list, 1, 3)
getcolaslist <- function(datalist, listNum, colNum) {
col <- list(NA)
for (i in 1:length(datalist[[listNum]])) {
col[[i]] <- datalist[[listNum]][[i]][[colNum]]
}
return(col)
}
getcolaslist(data_list, 1, 3)
getcolasvec <- function(data_list, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(data_list[[listNum]])) {
col[i] <- unlist(data_list[[listNum]][[i]][[colNum]])
}
return(col)
}
getcolasvec <- function(data_list, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(data_list[[listNum]])) {
col[i] <- unlist(data_list[[listNum]][[i]][[colNum]])
}
return(col)
}
getcolasvec <- function(data = data_list, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(data[[listNum]])) {
col[i] <- unlist(data[[listNum]][[i]][[colNum]])
}
return(col)
}
head(getcolasvec(data_list,1,1))
head(getcolasvec(1,1))
getcolasvec <- function(data, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(data[[listNum]])) {
col[i] <- unlist(data[[listNum]][[i]][[colNum]])
}
return(col)
}
getcolaslist <- function(data, listNum, colNum) {
col <- list(NA)
for (i in 1:length(data[[listNum]])) {
col[[i]] <- data[[listNum]][[i]][[colNum]]
}
return(col)
}
getdf <- function(data, listNum){
col1 <- getcolasvec(data_list, listNum, 1)
col2 <- getcolasvec(data_list, listNum, 2)
col4 <- getcolasvec(data_list, listNum, 4)
col5 <- getcolasvec(data_list, listNum, 5)
col3 <- getcolaslist(data_list, listNum, 3)
df <- data.frame(authorNum = col1, paperNum = col2, coauthor = col3, paperTitle = col4, journalTitle = col5)
return(df)
}
testdf <- getdf(data_list, 1)
col1 <- getcolasvec(data_list, listNum, 1)
col2 <- getcolasvec(data_list, listNum, 2)
col4 <- getcolasvec(data_list, listNum, 4)
col5 <- getcolasvec(data_list, listNum, 5)
col3 <- getcolaslist(data_list, listNum, 3)
col1 <- getcolasvec(data_list, 1, 1)
col2 <- getcolasvec(data_list, 1, 2)
col4 <- getcolasvec(data_list, 1, 4)
col5 <- getcolasvec(data_list, 1, 5)
col3 <- getcolaslist(data_list, 1, 3)
testdf <- data.frame(authorNum = col1, paperNum = col2, coauthor = col3, paperTitle = col4, journalTitle = col5)
testdf <- data.frame(authorNum = col1, paperNum = col2, paperTitle = col4, journalTitle = col5)
testdf$coauthor <- col3
View(testdf)
str(testdf[,3])
str(testdf[,5])
testdf[,3] <- as.character(testdf[,3])
str(testdf[,3])
testdf[1,3]
str(testdf[1,3])
rm(list = ls())
load("../data/profclean.RData")
# Use AGupta as an example, simulate a partition T
# by randomly putting 200 observations into cluster 1 and the other 377 into cluster 2
# Cluster assignment is appended as the 6th element in each observation, taking value 1 or 2
getcolasvec <- function(data, listNum, colNum) {
col <- rep(NA)
for (i in 1:length(data[[listNum]])) {
col[i] <- unlist(data[[listNum]][[i]][[colNum]])
}
return(col)
}
getcolaslist <- function(data, listNum, colNum) {
col <- list(NA)
for (i in 1:length(data[[listNum]])) {
col[[i]] <- data[[listNum]][[i]][[colNum]]
}
return(col)
}
getdf <- function(data, listNum){
col1 <- getcolasvec(data_list, listNum, 1)
col2 <- getcolasvec(data_list, listNum, 2)
col4 <- getcolasvec(data_list, listNum, 4)
col5 <- getcolasvec(data_list, listNum, 5)
col3 <- getcolaslist(data_list, listNum, 3)
df <- data.frame(authorNum = col1, paperNum = col2, paperTitle = col4, journalTitle = col5)
df$coauthor <- col3
df[,3] <- as.character(df[,3])
df[,4] <- as.character(df[,4])
return(df)
}
AGupta <- getdf(data_list,1)
View(AGupta)
data <- list(NA)
for (i in 1:14) {
data[[i]] <- getdf(data_list, i)
}
testdf <- data[[1]]
View(testdf)
save(data)
save(data, file = "../data/data.RData")
load("C:/Users/Brown/Documents/GitHub/Spr2017-proj4-team-11/data/data.RData")
